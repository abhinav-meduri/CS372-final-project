{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Model\n",
    "\n",
    "Complete ensemble model implementation combining PyTorch NN and Gradient Boosting with probability calibration using StackingClassifier and CalibratedClassifierCV.\n",
    "\n",
    "1. PyTorch neural network (best performing single model)\n",
    "2. Gradient Boosting (different algorithm = diversity)\n",
    "3. Stacking classifier with logistic regression meta-learner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.11.0)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/abhinavmeduri/projects/CS372-final-project/venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path().absolute().parent))\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "from sklearn.ensemble import GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, precision_score, recall_score, brier_score_loss, log_loss\n",
    "\n",
    "# Import PyTorch model class\n",
    "from src.app.pytorch_classifier import PyTorchPatentClassifier\n",
    "\n",
    "# Note: This notebook assumes PyTorch model is already trained and saved\n",
    "# The PyTorch model class is defined in src/app/pytorch_classifier.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (39979, 10), Validation: (8567, 10), Test: (8568, 10)\n"
     ]
    }
   ],
   "source": [
    "features_dir = Path(\"data/features\")\n",
    "\n",
    "X_train = np.load(features_dir/\"train_features_v2.X.npy\")\n",
    "y_train = np.load(features_dir/\"train_features_v2.y.npy\")\n",
    "X_val = np.load(features_dir/\"val_features_v2.X.npy\")\n",
    "y_val = np.load(features_dir/\"val_features_v2.y.npy\")\n",
    "X_test = np.load(features_dir/\"test_features_v2.X.npy\")\n",
    "y_test = np.load(features_dir/\"test_features_v2.y.npy\")\n",
    "\n",
    "with open(features_dir/\"feature_names_v2.json\", \"r\") as f:\n",
    "    feature_names = json.load(f)\n",
    "\n",
    "# Removed BM25 and CPC features (indices 0, 1, 6) to match 10-feature models (after ablation study) \n",
    "indices_to_remove = [0, 1, 6]\n",
    "indices_to_keep = [i for i in range(13) if i not in indices_to_remove]\n",
    "X_train = X_train[:, indices_to_keep]\n",
    "X_val = X_val[:, indices_to_keep]\n",
    "X_test = X_test[:, indices_to_keep]\n",
    "\n",
    "print(f\"Training: {X_train.shape}, Validation: {X_val.shape}, Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load PyTorch Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PyTorch model\n",
    "pytorch_model = PyTorchPatentClassifier()\n",
    "pytorch_model.load(Path('models/pytorch_nn'))\n",
    "\n",
    "# Prepare scaled features for meta-learner\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain PyTorch Model Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-features shape: (39979, 11)\n",
      "PyTorch predictions: 1 feature\n",
      "Original features: 10 features\n"
     ]
    }
   ],
   "source": [
    "# Get PyTorch model predictions (probabilities for class 1)\n",
    "pytorch_proba_train = pytorch_model.predict_proba(X_train)[:, 1]\n",
    "pytorch_proba_val = pytorch_model.predict_proba(X_val)[:, 1]\n",
    "pytorch_proba_test = pytorch_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Create meta-features: PyTorch predictions + original scaled features\n",
    "X_meta_train = np.column_stack([pytorch_proba_train, X_train_scaled])\n",
    "X_meta_val = np.column_stack([pytorch_proba_val, X_val_scaled])\n",
    "X_meta_test = np.column_stack([pytorch_proba_test, X_test_scaled])\n",
    "\n",
    "print(f\"Meta-features shape: {X_meta_train.shape}\")\n",
    "print(f\"PyTorch predictions: 1 feature\")\n",
    "print(f\"Original features: {X_train_scaled.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Stacking Ensemble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base model: Gradient Boosting (trained on PyTorch predictions + original features)\n",
    "# Meta-learner: Logistic Regression (learns to combine base model predictions)\n",
    "\n",
    "# The meta-features (X_meta) include:\n",
    "# 1. PyTorch model predictions (1 feature)\n",
    "# 2. Original scaled features (10 features)\n",
    "\n",
    "base_models = [\n",
    "    ('gb', GradientBoostingClassifier(n_estimators=100, max_depth=5, random_state=42))\n",
    "]\n",
    "\n",
    "meta_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "stacking = StackingClassifier(\n",
    "    estimators=base_models,\n",
    "    final_estimator=meta_model,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "stacking.fit(X_meta_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrate Probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrated_ensemble = CalibratedClassifierCV(\n",
    "    stacking,\n",
    "    method='sigmoid',\n",
    "    cv=5 # 5-fold cross-validation\n",
    ")\n",
    "\n",
    "calibrated_ensemble.fit(X_meta_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Ensemble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Metrics:\n",
      "  accuracy: 0.9158\n",
      "  precision: 0.9221\n",
      "  recall: 0.9067\n",
      "  f1: 0.9143\n",
      "  roc_auc: 0.9713\n",
      "  brier_score: 0.0663\n",
      "  log_loss: 0.2327\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = calibrated_ensemble.predict(X_meta_test)\n",
    "y_proba_test = calibrated_ensemble.predict_proba(X_meta_test)[:, 1]\n",
    "\n",
    "metrics = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_test),\n",
    "    'precision': precision_score(y_test, y_pred_test),\n",
    "    'recall': recall_score(y_test, y_pred_test),\n",
    "    'f1': f1_score(y_test, y_pred_test),\n",
    "    'roc_auc': roc_auc_score(y_test, y_proba_test),\n",
    "    'brier_score': brier_score_loss(y_test, y_proba_test),\n",
    "    'log_loss': log_loss(y_test, y_proba_test)\n",
    "}\n",
    "\n",
    "print(\"Test Metrics:\")\n",
    "for key, value in metrics.items():\n",
    "    print(f\"  {key}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Ensemble Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble model saved to: experimental/ensemble/models\n",
      "Metrics saved to: experimental/ensemble/results\n"
     ]
    }
   ],
   "source": [
    "ensemble_dir = Path(\"experimental/ensemble/models\")\n",
    "ensemble_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(ensemble_dir/\"ensemble_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(calibrated_ensemble, f)\n",
    "\n",
    "with open(ensemble_dir/\"scaler.pkl\", \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "results_dir = Path(\"experimental/ensemble/results\")\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(results_dir/\"ensemble_metrics.json\", \"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(f\"Ensemble model saved to: {ensemble_dir}\")\n",
    "print(f\"Metrics saved to: {results_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
